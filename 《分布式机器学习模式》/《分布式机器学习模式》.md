# 《分布式机器学习模式》

## 第二章 数据摄取模式
监控任何传入数据并执行必要的预处理步骤来准备模型训练
- 批处理模式：批处理模式通过小批量使用数据集来帮助处理内存中的大型数据集。
- 分片模式：分片模式将非常大的数据集准备为位于不同计算机上的较小数据块。
- 缓存模式：缓存模式通过缓存以前访问的数据，使多轮训练的数据获取更加高效，这些数据可以重复用于同一数据集上的其他轮次模型训练。

## 第三章 分布式训练模式
### 模式
- 参数服务器模式：解决模型（参数）太大无法在单个机器上训练的问题。
- 集体通信模式：
- 
![03-07.png](imgs/03-07.png)
具有单个参数服务器的机器学习训练

![03-08.png](imgs/03-08.png)
具有多个参数服务器的机器学习训练\
由于所有工作线程都以异步方式执行计算，因此每个工作线程节点用于计算梯度的模型分区可能不是最新的。为了保证每个 Worker 节点使用的模型分区或服务器存储的每个参数分区都是最新的，我们必须不断在 Worker 节点之间拉取和推送模型的更新。
尽管 parameter server 模式在此方案中很有用，但它是专门为训练具有大量参数的模型而设计的。

![03-15.png](imgs/03-15.png)
仅包含Worker节点的分布式模型训练组件。每个工作程序都存储了整个模型参数集的副本，并使用数据分区来计算梯度。